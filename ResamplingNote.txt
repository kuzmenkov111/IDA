caret package
** credit, baseline accuracy rate to beat: 70%

tuning parameters
** non-linear support vector machine: tuning parameters from 2^-2 to 2^7
** repeated cross validation: 10-fold cross-validation 5 times
** choosing the parameter
**** 'one-standard error' - from numerically optimal case, accept the simplest case whin one standard error of accuracy (eg mean accuracy 75% at 8 with 0.7% std, select the simplest no lower than 75%-0.7%)
**** set acceptable loss of accuracy (4%), accpet the simplest no lower than 75% - 4%.

data split
** holdout validation are not recommended without a supporting reason
**** a single model evaluation has limited to characterize the uncertainty in the results

**
**

** for small sample size, repeated 10-fold cross-validation
**** good bias and variance property
**** computational cost is not large
** for model selecton between models
**** bootstrap may be used for low variance <--
** for large sample size
**** differences between resampling strategies less propount
**** computational efficiency becomes more important
**** 10-fold cross-validation should provide acceptable bias-variance profile with relatively quick computing time


** potential bias when estimating model performance duing parameter tuning


